- attributes:
  - doc: Value is Stores points in space over time. The data[] array structure is
      [num samples][num spatial dimensions]
    name: help
    type: text
    value: Stores points in space over time. The data[] array structure is [num samples][num
      spatial dimensions]
  datasets:
  - doc: Description defining what exactly 'straight-ahead' means.
    name: reference_frame
    type: text
  - attributes:
    - doc: Value is meter
      name: unit
      type: text
      value: meter
    doc: 2-D array storing position or direction relative to some reference frame.
    name: data
    type: number
  doc: 'Direction, e.g., of gaze or travel, or position. The TimeSeries::data field
    is a 2D array storing position or direction relative to some reference frame.
    Array structure: [num measurements] [num dimensions]. Each SpatialSeries has a
    text dataset reference_frame that indicates the zero-position, or the zero-axes
    for direction. For example, if representing gaze direction, "straight-ahead" might
    be a specific pixel on the monitor, or some other point in space. For position
    data, the 0,0 point might be the top-left corner of an enclosure, as viewed from
    the tracking camera. The unit of data will indicate how to interpret SpatialSeries
    values.'
  neurodata_type: TimeSeries
  neurodata_type_def: SpatialSeries
- attributes:
  - doc: Value is General container for storing behavorial epochs
    name: help
    type: text
    value: General container for storing behavorial epochs
  doc: TimeSeries for storing behavoioral epochs.  The objective of this and the other
    two Behavioral interfaces (e.g. BehavioralEvents and BehavioralTimeSeries) is
    to provide generic hooks for software tools/scripts. This allows a tool/script
    to take the output one specific interface (e.g., UnitTimes) and plot that data
    relative to another data modality (e.g., behavioral events) without having to
    define all possible modalities in advance. Declaring one of these interfaces means
    that one or more TimeSeries of the specified type is published. These TimeSeries
    should reside in a group having the same name as the interface. For example, if
    a BehavioralTimeSeries interface is declared, the module will have one or more
    TimeSeries defined in the module sub-group "BehavioralTimeSeries". BehavioralEpochs
    should use IntervalSeries. BehavioralEvents is used for irregular events. BehavioralTimeSeries
    is for continuous data.
  groups:
  - doc: IntervalSeries object containing start and stop times of epochs
    neurodata_type: IntervalSeries
  name: BehavioralEpochs
  neurodata_type: Interface
  neurodata_type_def: BehavioralEpochs
- attributes:
  - doc: Value is Position data, whether along the x, xy or xyz axis
    name: help
    type: text
    value: Position data, whether along the x, xy or xyz axis
  doc: TimeSeries for storing behavioral events. See description of <a href="#BehavioralEpochs">BehavioralEpochs</a>
    for more details.
  groups:
  - doc: TimeSeries object containing irregular behavioral events
    neurodata_type: TimeSeries
  name: BehavioralEvents
  neurodata_type: Interface
  neurodata_type_def: BehavioralEvents
- doc: TimeSeries for storing Behavoioral time series data.See description of <a href="#BehavioralEpochs">BehavioralEpochs</a>
    for more details.
  groups:
  - doc: TimeSeries object containing continuous behavioral data
    neurodata_type: TimeSeries
  name: BehavioralTimeSeries
  neurodata_type: Interface
  neurodata_type_def: BehavioralTimeSeries
- attributes:
  - doc: Value is Eye-tracking data, representing pupil size
    name: help
    type: text
    value: Eye-tracking data, representing pupil size
  doc: Eye-tracking data, representing pupil size.
  groups:
  - doc: TimeSeries object containing time series data on pupil size
    neurodata_type: TimeSeries
  name: PupilTracking
  neurodata_type: Interface
  neurodata_type_def: PupilTracking
- attributes:
  - doc: Value is Eye-tracking data, representing direction of gaze
    name: help
    type: text
    value: Eye-tracking data, representing direction of gaze
  doc: Eye-tracking data, representing direction of gaze.
  groups:
  - doc: SpatialSeries object containing data measuring direction of gaze
    neurodata_type: SpatialSeries
  name: EyeTracking
  neurodata_type: Interface
  neurodata_type_def: EyeTracking
- attributes:
  - doc: Value is Direction as measured radially. Spatial series reference frame should
      indicate which direction corresponds to zero and what is the direction of positive
      rotation
    name: help
    type: text
    value: Direction as measured radially. Spatial series reference frame should indicate
      which direction corresponds to zero and what is the direction of positive rotation
  doc: With a CompassDirection interface, a module publishes a SpatialSeries object
    representing a floating point value for theta. The SpatialSeries::reference_frame
    field should indicate what direction corresponds to 0 and which is the direction
    of rotation (this should be clockwise). The si_unit for the SpatialSeries should
    be radians or degrees.
  groups:
  - doc: SpatialSeries object containing direction of gaze travel
    neurodata_type: SpatialSeries
  name: CompassDirection
  neurodata_type: Interface
  neurodata_type_def: CompassDirection
- attributes:
  - doc: Value is Position data, whether along the x, xy or xyz axis
    name: help
    type: text
    value: Position data, whether along the x, xy or xyz axis
  doc: Position data, whether along the x, x/y or x/y/z axis.
  groups:
  - doc: SpatialSeries object containing position data
    neurodata_type: SpatialSeries
  name: Position
  neurodata_type: Interface
  neurodata_type_def: Position
- attributes:
  - doc: Value is Image stacks whose frames have been shifted (registered) to account
      for motion
    name: help
    type: text
    value: Image stacks whose frames have been shifted (registered) to account for
      motion
  doc: 'An image stack where all frames are shifted (registered) to a common coordinate
    system, to account for movement and drift between frames. Note: each frame at
    each point in time is assumed to be 2-D (has only x & y dimensions).'
  groups:
  - datasets:
    - doc: Path to linked original timeseries
      name: original_path
      type: text
    doc: One of possibly many.  Name should be informative.
    groups:
    - doc: Stores the x,y delta necessary to align each frame to the common coordinates,
        for example, to align each frame to a reference image.
      name: xy_translation
      neurodata_type: TimeSeries
    - doc: Image stack with frames shifted to the common coordinates.
      name: corrected
      neurodata_type: ImageSeries
    links:
    - doc: HDF5 Link to image series that is being registered.
      name: original
      target_type: ImageSeries
    name: <image stack name>/+
  name: MotionCorrection
  neurodata_type: Interface
  neurodata_type_def: MotionCorrection
